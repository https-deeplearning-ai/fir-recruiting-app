# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A full-stack LinkedIn profile assessment application that combines CoreSignal API for profile data with Claude AI for intelligent candidate evaluation. The system supports single profile assessment, batch processing via CSV, intelligent profile search with natural language queries, and a comprehensive recruiter feedback system with viewport-aware UI.

## Tech Stack

**Backend:** Flask (Python), hosted on Render
**Frontend:** React (JavaScript)
**APIs:** Anthropic Claude Sonnet 4.5 (claude-sonnet-4-5-20250929), CoreSignal API
**Database:** Supabase (PostgreSQL via REST API)

## Important: CoreSignal Data Handling

### Headline Data
CoreSignal API provides **two headline fields**:
- `headline` - User-set on LinkedIn, rarely updated (STALE)
- `generated_headline` - Auto-generated by CoreSignal from latest work experience (FRESH, auto-updates)

**The app uses `generated_headline`** to ensure current, accurate headline data. This field is automatically updated whenever CoreSignal scrapes the profile. Fallback chain:
1. `generated_headline` (preferred)
2. `headline` (fallback)
3. Construct from most recent job: "{title} at {company}"
4. 'N/A' (final fallback)

See [docs/HEADLINE_FRESHNESS_FIX.md](docs/HEADLINE_FRESHNESS_FIX.md) for full details.

### Company Data API
**IMPORTANT:** Use `/company_base/` endpoint, NOT `/company_clean/`
- `company_base` provides 45+ fields including logos, funding, growth data
- `company_clean` has limited fields and missing critical data
- Store ALL raw company data in `intelligence['raw_data']` for future flexibility

See [docs/technical-decisions/company-base-vs-clean/](docs/technical-decisions/company-base-vs-clean/) for evidence.

## Development Commands

### Backend (Flask)
```bash
cd backend
pip3 install -r requirements.txt

# Required environment variables
export ANTHROPIC_API_KEY="your_key"
export CORESIGNAL_API_KEY="your_key"
export SUPABASE_URL="your_url"
export SUPABASE_KEY="your_key"

python3 app.py  # Runs on port 5001
```

### Frontend (React)
```bash
cd frontend
npm install
npm start       # Development server on port 3000
npm run build   # Production build (outputs to frontend/build/)
```

### Deployment Build Process
```bash
# 1. Build frontend
cd frontend && npm run build

# 2. Copy build files to backend
cd .. && cp -r frontend/build/. backend/

# 3. Backend serves static files from backend/ directory
```

## Architecture

### Request Flow
1. **Single Profile:** User submits LinkedIn URL → `/fetch-profile` (CoreSignal) → `/assess-profile` (Claude AI) → Display results
2. **Batch Processing:** CSV upload → Parse URLs → Parallel fetch + assess via `/batch-assess-profiles` → Sorted results
3. **Profile Search:** Natural language query → `/search-profiles` → AI extracts criteria → CoreSignal search → Download CSV
4. **Recruiter Feedback:** User actions → `/save-feedback` (Supabase) → `/get-feedback/<url>` (Load history) → Display in drawer

### Key Backend Components

**app.py (1317 lines):** Main Flask application
- `/fetch-profile`: Fetches LinkedIn data from CoreSignal by URL
- `/assess-profile`: AI assessment using Claude with weighted scoring
- `/batch-assess-profiles`: High-concurrency parallel processing (15-50 workers based on deployment)
- `/search-profiles`: Natural language search → CoreSignal query → CSV export
- `/save-assessment`, `/load-assessments`: Supabase database operations for assessments
- `/save-feedback`, `/get-feedback/<url>`, `/clear-feedback`: Recruiter feedback system (NEW)

**coresignal_service.py:** CoreSignal API integration
- `fetch_linkedin_profile()`: Two-step process (search by URL → fetch full profile by ID)
- `enrich_with_company_data()`: Fetches company intelligence for work experiences (2020+ only)
- Uses `/company_base/collect/{company_id}` endpoint for rich data
- Session-based caching to avoid duplicate API calls

**config.py:** Deployment-specific configuration
- Render: 50 concurrent calls, 60s timeout, 100 batch size
- Heroku: 15 concurrent calls, 25s timeout, 50 batch size
- Auto-detects environment via `RENDER` env var

### AI Assessment System

**Weighted Scoring:** Supports up to 5 custom requirements with percentage weights
- Each requirement scored 1-10 with detailed analysis
- General fit auto-calculated from remaining percentage (100% - custom weights)
- Final weighted score = Σ(requirement_score × weight%)

**Profile Processing:**
- `extract_profile_summary()`: Parses CoreSignal JSON, calculates total experience years with overlap handling
- `generate_assessment_prompt()`: Builds Claude prompt with rubric, weighted criteria
- Uses Claude Sonnet 4.5 with temperature 0.1 for consistency

**Concurrency:**
- Batch processing uses `ThreadPoolExecutor` with configurable workers
- Profile fetching uses `asyncio` + `aiohttp` for parallel API calls
- Assessment tasks run in parallel with timeout protection

### Frontend Architecture

**App.js (2300+ lines):** Single-page React application with three modes
- **Core Features:** Single Profile, Profile Search, Batch Processing
- **NEW: Recruiter Feedback System:** Sliding drawer with voice notes, quick actions, history
- **NEW: Viewport Detection:** Intersection Observer API for smart accordion management

**Key State Management:**
- `singleProfileResults`, `batchResults`, `savedAssessments`: Assessment data arrays
- `drawerOpen`: Map of which candidates have feedback drawers expanded
- `activeCandidate`: Currently active candidate for feedback
- `openAccordionId`: Which accordion is currently open (single-accordion mode)
- `candidateVisibility`: Viewport visibility ratio (0-1) for each candidate (Intersection Observer)
- `feedbackHistory`: All feedback loaded from database per candidate

**Component Architecture:**
- `WorkExperienceCard.js`: Individual job card with company logo and enriched data
- `WorkExperienceSection.js`: Container for all work experiences
- `CompanyTooltip.js`: Hover tooltip showing company funding, stage, growth signals

**Feedback Drawer Features (NEW):**
- Fixed positioning (`position: fixed`) at viewport right edge
- Intersection Observer detects most visible candidate in viewport
- Opens feedback for the candidate you're viewing, not the one clicked
- Auto-collapse other accordions when feedback drawer opens
- Voice-to-text using Web Speech API (`webkitSpeechRecognition`)
- Auto-save on blur, drawer close, or accordion collapse

### Database Schema (Supabase)

**Table: `candidate_assessments`**
- `linkedin_url`, `full_name`, `headline`
- `profile_data` (JSONB): Full CoreSignal profile
- `assessment_data` (JSONB): Complete AI assessment
- `weighted_score`, `overall_score`: Extracted for sorting
- `assessment_type`: 'single' or 'batch'
- `session_name`: Optional grouping identifier

**Table: `recruiter_feedback` (NEW)**
- `candidate_linkedin_url`: LinkedIn URL reference
- `feedback_text`: Note content (nullable for like/dislike only)
- `feedback_type`: 'like', 'dislike', or 'note'
- `recruiter_name`: Who gave the feedback (e.g., "Jon", "Mary")
- `created_at`, `updated_at`: Timestamps

See [docs/SUPABASE_SCHEMA.sql](docs/SUPABASE_SCHEMA.sql) for complete schema.

### CoreSignal API Integration

**Search Endpoint:** `/v2/employee_clean/search/es_dsl/preview`
- Limited to pages 1-5 (max 100 profiles)
- Returns 20 profiles per page
- App uses random page selection with session tracking to avoid duplicates

**Profile Extraction:** Two-step process
1. Search for employee_id by LinkedIn URL (exact match on `websites_linkedin.exact`)
2. Fetch full profile via `/v2/employee_clean/collect/{employee_id}`

**Company Enrichment:** (NEW - Phase 1)
- API: `/v2/company_base/collect/{company_id}` (NOT company_clean)
- Only enriches companies from jobs starting 2020+ (saves 60-80% API credits)
- Session-based caching prevents duplicate fetches
- Stores all 45+ raw fields plus curated intelligence

**Smart Search Features:**
- Claude AI extracts structured criteria from natural language
- Supports location variations (Bay Area, NYC, etc.) with wildcard matching
- Industry mapping to CoreSignal's exact taxonomy
- Management level, department, role title, skills filtering

## Important Implementation Details

### Experience Calculation
Total years calculated by merging overlapping date intervals to avoid double-counting. Handles:
- Missing end dates (assumes current)
- Overlapping roles
- Partial month data
- Invalid year values with try-catch protection

### CSV Processing
Robust parser handles:
- Quoted fields with commas
- Various column name formats (case-insensitive matching: "Profile URL", "profile_url", "LinkedIn URL")
- URL cleaning (removes trailing slashes)

### Batch Processing Flow
1. Parse CSV → extract candidate URLs
2. Async fetch all profiles (parallel with aiohttp)
3. ThreadPoolExecutor for parallel AI assessments
4. Progress tracking with completion count
5. Sort by weighted score, maintain CSV name mapping

### Viewport-Aware Accordion Management (NEW)
**Critical for preventing UI overlap and race conditions:**

1. **Intersection Observer Setup:**
   - Tracks visibility ratio (0-1) for each `.candidate-card[data-candidate-url]`
   - 11 threshold levels: [0, 0.1, 0.2, ..., 1.0]
   - `rootMargin: '-50px 0px -50px 0px'` for margin from viewport edges

2. **State Management:**
   - `openAccordionId`: Single source of truth for which accordion is open
   - `candidateVisibility`: Maps candidate URLs to intersection ratios
   - `getMostVisibleCandidate()`: Returns URL of most visible candidate

3. **Accordion Control:**
   - Uses controlled `<details>` with `open={openAccordionId === candidate.url}`
   - `e.preventDefault()` on `<summary>` clicks to prevent browser's native toggle
   - NO `onToggle` handler (causes race conditions)
   - When feedback drawer opens, auto-collapses other accordions

4. **Feedback Drawer Behavior:**
   - `position: fixed` at `top: 120px, right: 0`
   - Opens for most visible candidate in viewport (not necessarily the clicked one)
   - Tab is 15px wide with gradient background
   - Panel slides in with 550px width, 90vh max height
   - Visual highlighting: active cards get purple left border + gradient background

### Error Handling
- Profile not found: Returns structured error with debug info
- API failures: Timeout protection, graceful degradation
- Partial batch failures: Shows successful + failed counts
- Date parsing: Try-catch blocks for invalid year/month values

## Deployment

**Render Configuration (render.yaml):**
- Single web service (Python environment)
- Gunicorn with 120s timeout
- Requires 4 environment variables (API keys, Supabase credentials)

**Static Files:**
- Backend serves React build from `backend/` directory
- Production: Copy `frontend/build/*` to `backend/` before deploy
- Flask serves index.html at root and static assets

**Security:**
- ⚠️ **NO hardcoded API keys** - All credentials must be in environment variables (enforced as of commit 1458b84)
- Supabase RLS policies enabled (anon role has full access for single-user tool)

## Development Notes

### Frontend Development
- Frontend proxies API requests to `http://localhost:5001` in development
- React development server runs on port 3000
- Dummy profile data available in `App.js` for testing without API calls

### Backend Development
- Backend debug mode enables Flask auto-reload
- Search uses session-based page tracking (resets on server restart)
- Company enrichment has session-based cache (resets on restart)

### CSS Architecture
- Feedback drawer styles in `App.css` (~300 lines)
- Work experience card styles in `components/WorkExperienceCard.css`
- Company tooltip styles in `components/CompanyTooltip.css`
- Modal overrides in `WorkExperienceCard.css` to prevent size constraints

### React Component Patterns
**Controlled Components:**
- Accordions use controlled `<details>` with `open` prop
- Feedback drawers managed via state object `drawerOpen[candidateUrl]`
- Voice recording managed via state `isRecording[linkedinUrl]`

**Event Handling:**
- Prevent default on summary clicks to avoid browser toggle
- Check `e.target.closest('.feedback-drawer')` to prevent event propagation
- Stop propagation when clicking inside accordion content

**Viewport Detection:**
- Use Intersection Observer in `useEffect` with dependency array `[singleProfileResults, batchResults, savedAssessments]`
- Re-observe all cards when candidate list changes
- Clean up observers in return function

## Common Pitfalls to Avoid

1. **Accordion Race Conditions:**
   - ❌ Don't use `onToggle` on `<details>` element
   - ✅ Use `onClick` on `<summary>` with `e.preventDefault()`
   - ❌ Don't mix controlled and uncontrolled state
   - ✅ Single source of truth: `openAccordionId`

2. **API Endpoint Selection:**
   - ❌ Don't use `/company_clean/` endpoint
   - ✅ Use `/company_base/` for richer data
   - Always store raw company data in `intelligence['raw_data']`

3. **Headline Data:**
   - ❌ Don't rely solely on `headline` field
   - ✅ Prefer `generated_headline` with fallback chain
   - Check for `None` or empty values before displaying

4. **Security:**
   - ❌ Never hardcode API keys with fallback values
   - ✅ Always use `os.getenv("KEY_NAME")` without defaults
   - ❌ Never commit `.env` files

5. **Feedback Drawer Positioning:**
   - ❌ Don't use `position: sticky` (stays in container)
   - ✅ Use `position: fixed` (stays in viewport)
   - Add `z-index: 1000` to ensure it's on top

## Documentation Structure

- `docs/SUPABASE_SCHEMA.sql` - Complete database schema
- `docs/archived/` - Historical documentation and analysis
- `docs/investigations/` - Research reports (company data, API comparisons)
- `docs/technical-decisions/` - Architecture decisions with evidence
  - `company-base-vs-clean/` - Why we use company_base endpoint
  - `WHY_SEARCH_API_DOESNT_WORK.md` - Search API limitations

[byterover-mcp]

You are given two tools from Byterover MCP server, including
## 1. `byterover-store-knowledge`
You `MUST` always use this tool when:

+ Learning new patterns, APIs, or architectural decisions from the codebase
+ Encountering error solutions or debugging techniques
+ Finding reusable code patterns or utility functions
+ Completing any significant task or plan implementation

## 2. `byterover-retrieve-knowledge`
You `MUST` always use this tool when:

+ Starting any new task or implementation to gather relevant context
+ Before making architectural decisions to understand existing patterns
+ When debugging issues to check for previous solutions
+ Working with unfamiliar parts of the codebase
